
For current commit message:  

'finished model and got cli to pull title instances from model#all rather than from Scraper'



GOALS to include in ReadMe:

1. Make cli user friendly
DONE 2. Make model able to store different urls to scrape ... attracessor from Scraper?
3. Make model able to store article titles and content but don't necessarily connect it to specific scraped titles and contents

 Steps for next time:

1. Finish parsing cli to make information more user friendly
2. Finish making model workable for instantiating title and content and connect from cli, not scraper?
    practice metaprogramming
3. finish main steps below



Testing out model methods

1. Checking out any issues with TOS for scraping DONE
2. Start Readme DONE

3. Create CLI to return numbered list of articles DONE

User will be able to choose from numbered list of article titles to see content

4.  Build out Scraper to scrape this page for attributes IN PROCESS
5.  Build out module DONE
6.  Make sure CLI works IN PROCESS
7.  Finish/proof Readme
8.  Finish pushing gem to rubygems
9.  Blog (all along) IN PROCESS
10. Make sure all steps in lab are finished
11. Submit project


Refactoring:

intantiate content as well as titles in model

use a find method to match home page title and title on content page in case there's a problem with the source code

pull titles from hash directly rather than from an array of hash/es

use input methods with now-playing to make sure input is an integer

consdier using @@all ||= scraped info like now playing

make sure it's easy for any new page from wikihow to be scraped, not just the one currently in the project

add titles to specific numbered methods from the related content site



For blogging later:

I found that you need to use both the literal and the abstract. You can "think abstractly" but only to a point. You need to use literal examples, plugging in real instances, objects, and methods, to make sure the abstract works (and not to cause a nervous breakdown on your quest to become the most amazing coder in history in a few months time :) )

